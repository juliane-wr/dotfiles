{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliane-wr/dotfiles/blob/master/060301_mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSl4Ypq8lDHF"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfALDIddlDHH"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset\n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*?\n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC0YZG4tlDHH"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits?\n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFuPzMlQlDHI"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qmtmLSklDHI"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngs0MtstlDHI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBT4Gr_3lDHJ"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esW7TLAOlDHJ"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8ykc4sXlDHJ",
        "outputId": "292bf075-1589-4339-f4b0-eb767e344e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLqzF7j7lDHJ"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez6qA7zGlDHJ"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "1oyr_Q6flDHK",
        "outputId": "0d33251a-0d8b-45a9-ce1f-0a7d90fbb120"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ccfa5ac6620>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(X_train[19], cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFlADQPrlDHK"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RzvJ_HTlDHK"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255.\n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2Zir239lDHK"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.**\n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "UC3EzwfTlDHK"
      },
      "outputs": [],
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGLSF0cdlDHK"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEzTgsK3lDHK",
        "outputId": "5d5d492b-3fa0-4554-e073-8153aad62560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PyLWXsvlDHK"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJdJAtlnlDHL"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu3xG_lFlDHL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de0M9u4TlDHL"
      },
      "outputs": [],
      "source": [
        "X_train = expand_dims(X_train, -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = expand_dims(X_test, -1)"
      ],
      "metadata": {
        "id": "_wI1aePIrARM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLzQqUBrlDHL"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGmcnB4nlDHL"
      },
      "source": [
        "One more thing to do for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì\n",
        "\n",
        "* Use **`to_categorical`** to transform your labels.\n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRXId7mklDHL",
        "outputId": "291b088e-8b80-42e9-e18d-773d65bded15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train,num_classes = 10)\n",
        "y_test_cat = to_categorical(y_test,num_classes = 10)\n",
        "y_test_cat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pZ737gqlDHL"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfF115WAlDHL"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUZtxXWFlDHL"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLV21xtIlDHM"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXMkSVsrlDHM"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has:\n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer,\n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U55ozwfflDHM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), input_shape=(28, 28, 1), activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), padding='same', activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(10, activation='relu')) # intermediate layer\n",
        "\n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    ### Model compilation\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFZDH4D6lDHM"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì\n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyj7zhv4lDHM",
        "outputId": "71a5e842-9008-44d2-9429-142b4b13bbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 8)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5770      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7184 (28.06 KB)\n",
            "Trainable params: 7184 (28.06 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = initialize_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th4lA8CJlDHM"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nEBrM9OlDHM"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì\n",
        "\n",
        "Initialize your model and fit it on the train data.\n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**.\n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Wz41AelDHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da40546-fda3-477c-c9b3-58c25145aa9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ccf9e5c1f60>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(patience=30, restore_best_weights=True)\n",
        "model.fit(X_train, y_train_cat,\n",
        "          batch_size=16, # Batch size -too small--> no generalization\n",
        "          epochs=5,    #            -too large--> slow computations\n",
        "          validation_split=0.3,\n",
        "          callbacks=[es],\n",
        "          verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-mfFT-0lDHN"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "NdbonYeylDHN"
      },
      "source": [
        "> YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO-uMCYwlDHN"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32:\n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss`\n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUT_SkbQlDHR"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgsajExJlDHR"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì\n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "Z1ZROB0QlDHR"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test,y_test_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7gQ0iC2lDHR"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdIBHkR3lDHR"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}